## 秋招腾讯TEG提前批

#### 一面

1. 键入一个域名，整体怎么做流转的，要很详细

- 首先会将域名发送给DNS服务器做解析，按照顺序是先本地域名服务器，没有找到的话就到更上层，直到查询到这个url的IP。`（检查本地缓存，操作系统缓存甚至路由器缓存，DNS递归查询）`
- 在此后，会通过三次握手的方式与对面服务器建立连接：首先发送一个TCP包，包含本地进程的编号`(同步序列编号)`，对面服务器接收后返回ACK信号以及客户端进程编号+1的数值，并同时返回自己内部进程的编号，本地接收到后，如果数值确实是本地进程编号+1，则也同样返回ACK与对面进程编号+1的值，服务端接收到后确认值，如果正确则成功建立了连接。
- 接着，会根据请求信息拼接HTTP报文，包括HTTP请求头这些，并向域名解析获得的IP发送请求。
- 然后，发送请求过程中，这个HTTP请求先是在网络的应用层，根据请求大小等请求的基本信息，将其拆分或者合并成TCP（若是TCP而不是UDP）的请求，并拼接上TCP的请求头，这一步是到了传输层。接着再根据本机的基本信息拼接上IP等网络层头信息，最后将这些信息(添加mac地址)转换为电信号，通过网卡向外传输。经过交换机、路由器等网络中间件，将请求发送到目标服务器。
- 这个请求也是经过对吗的网络接口层、网络层、传输层和应用层，根据端口号抵达了对吗服务器中对应的服务，进行指定的服务内部逻辑处理后，将结果返回给本地。
- 请求全部完毕后，客户端会发送FIN信号，服务端接收后返回一个ACK，同时再发送一个FIN信号给客户端，客户端也返回一个ACk，至此，四次挥手也结束了。

2. 然后http协议那里，对于粘包问题，我们可以怎么解决。追问: 在http协议中，怎么判断拆包后组装后是组装完了，而不是一部分

- 粘包问题主要发生在TCP传输层协议中，多个发送的TCP包在接收方合并成了一个被接收，导致多条消息合并在一起，没有明显的边界。有多种解决的方法：
- 1 设置消息长度为定长，接收方可用获取定长的消息来解析，当然由于消息的多元化和复杂性，平时不会采用
- 2 添加消息的分隔符，接收方可用通过分隔符来确认消息，业界常使用的一种方法
- 3 我们可以在消息头上添加一个字段，标识这个应用层包的长度，接收方根据该字段获取数据。
- TCP中会使用Nagle算法，将小数据放入缓存中，等缓存满了再一起发送到接收端
- Http协议中有不同的数据传输方式，ContentLength模式和ChunkedTransfer模式，前者标识消息体长度，若累计接收的字节数等于Content-length的长度即为组装完成。后者标识消息体分块传输，最后以长度为0的块结束，通过识别这个块就能够判断是否组装完了。

3. 尝试推导redis是怎么做分布式的，如何保证写入一样数据库 即使某些库发生了崩溃，数据仍然存在

- redis主要是通过主从同步的方式实现写入的数据库和崩溃的数据库的数据同步。其中有全量同步和增量同步两种。
- 我认为这个问题首先得说一下Redis的持久化方式，有RDB和AOF两种方式，RDB是生成紧凑的二进制文件，可能会丢掉最后一次二进制化后的文件，而AOF能够将每次写操作都记录下来，但文件较大。
- 在从节点第一次连接到主节点时会进行全量同步，也就是使用RDB文件实现同步，这种情况是在主节点判断RDB文件比增量命令更高效的时候决定的。
- 而增量同步则依赖积压缓冲区，主节点会为每个从节点创建一个replication buffer用于实时传输写命令，主从这样也能够共享复制进度，实现同步。
- 这样，如果从数据库发生了崩溃，可以在重启后根据replication buffer和自身复制进度的offset进行对比，在新增数据没有超过replication buffer的情况下，可以进行崩溃期间数据的增量复制，如果新增数据超出了缓存，只能重新实现全量复制。
- 如果主数据库发生崩溃，可以使用哨兵机制，从健康的从节点中选取复制最完整的节点作为新的主节点，恢复可用。

4. raft协议里面为什么是n/2+1认为ok

核心原因是避免脑裂与确保唯一性。集群中最多只能有一个合法的leader，一旦超过半数节点认可某个决策，就代表这个决策是最终且唯一的，不会被后续操作推翻。避免出现多个子集群各自为政。

5. a函数调用b函数，汇编角度怎么发生的

- 首先是调用前的准备：
- 先将b函数需要的参数通过寄存器进行传递，执行call b命令，保存这里call命令的下一条指令地址后，跳转到b函数的执行区域
- 接着就是调用函数b的执行
- 首先建立新的栈帧，保存调用者a函数的栈帧底部，并设置新的栈帧底部，还要为b函数的局部变量分配内存空间
- 从寄存器中读取参数，进行函数的计算，将结果存入执行结果寄存器中
- 释放局部变量空间，将栈基址从b函数移动回a函数的栈基址，自动从栈中弹出返回地址并跳转到a函数执行call b的下一条指令
- 继续执行下一条，a函数可用从寄存器中获取b函数的返回结果
- **总结一下**：核心就是a函数调用b函数的时候，寄存器会记录a的栈基址以及调用下一条指令的地址，再进入b。进入b后会为它分配内存以及新的栈基址，在计算结束后会自动弹出地址并跳转到a调用b后的地址，并切换栈基址，保存b的返回值，接着进行下一次计算。

6. 算法：（1）字符串转16进制，并且16进制转字符串 

```java
public String toHex(int num) {
    if (num == 0) {
        return "0";
    }
    StringBuffer sb = new StringBuffer();
    for (int i = 7; i >= 0; i --) {
        int val = (num >> (4 * i)) & 0xf;
        if (sb.length() > 0 || val > 0) {
            char digit = val < 10 ? (char) ('0' + val) : (char) ('a' + val - 10);
            sb.append(digit);
        }
    }
    return sb.toString();
}

public String hexToString(String hex) {
    if (hex == null || hex.isEmpty()) {
        return "";
    }
    StringBuilder result = new StringBuilder(hex.length() / 2);
    for (int i = 0; i < hex.length(); i += 2) {
        String hexPair = hex.substring(i, Math.min(i + 2, hex.length()));
        int decimal = Integer.parseInt(hexPair, 16);
        result.append((char) decimal);
    }
    
    return result.toString();
}
```

7. 算法：（2）实现lru，并且key.size() << value.size() （进阶版：多线程实现）

```java
// 单线程
public class LRUCache<K,V> {

    class Node<K,V> {
        K key;
        V value;
        Node<K,V> prev, next;
        public Node() {}
        public Node(K key, V value) {
            this.key = key;
            this.value = value;
        }
    }

    private int capacity;
    private HashMap<K,Node> map;
    private Node<K,V> head;
    private Node<K,V> tail;
    // 锁
    private final ReentrantLock lock;

    public LRUCache(int capacity) {
        this.capacity = capacity;
        this.map = new HashMap<>(capacity);
        this.head = new Node<>();
        this.tail = new Node<>();
        this.head.next = tail;
        this.tail.prev = head;
    }

    public V get(K key) {
        Node<K,V> node = map.get(k)
        if (node == null)
            return null;
        
    }

    private void moveToFront(Node node) {
        removeNode(node);
        addToHead(node);
    }

    private Node removeTail() {
        Node node = tail.prev;
        removeNode(node);
        map.remove(node.key);
        return node;
    }

    private addToHead(Node<K,V> node) {
        node.prev = head;
        node.next = head.next;
        head.next.prev = head.next;
        head.next = newNode;
    }

    private removeNode(Node<K,V> node) {
        node.prev.next = node.next;
        node.next.prev = node.prev;
    }

    // 获取缓存值
    public String get(String key) {
        lock.lock();
        try {
            if (!map.containsKey(key))
                return "";
            Node node = map.get(key);
            moveToFront(node);
            return node.value;
        } finally {
            lock.unlock();
        }
    }

    // 添加或更新缓存
    private void put(String key, String value) {
        lock.lock();
        try {
            if (map.containsKey(key)) {
                Node node = map.get(key);
                node.value = value;
                moveToFront(node);
                return;
            }

            if (map.size() >= capacity)
                removeTail();

            Node newNode = new Node(key, value);
            map.put(key, newNode);
            addToFront(newNode);
        } finally {
            lock.unlock();
        }
    }

    // 获取缓存大小
    public int size() {
        lock.lock();
        try {
            return map.size();
        } finally {
            lock.unlock();
        }
    }
}


{
    // 若使用concurrentHashMap

    // get方法
    public String get(String key) {
        Node node = map.get(key);
        if (node == null) {
            return "";
        }
        
        // 读操作也需要加锁，因为需要移动节点到链表头部
        lock.lock();
        try {
            // 双重检查，防止在等待锁的过程中节点被其他线程移除
            node = map.get(key);
            if (node == null) {
                return "";
            }
            removeNode(node);
            addToFront(node);
            return node.value;
        } finally {
            lock.unlock();
        }
    }

    // put方法
    public void put(String key, String value) {
        // 先检查是否已存在，避免不必要的锁获取
        Node node = map.get(key);
        if (node != null) {
            lock.lock();
            try {
                // 双重检查
                node = map.get(key);
                if (node != null) {
                    node.value = value;
                    removeNode(node);
                    addToFront(node);
                    return;
                }
            } finally {
                lock.unlock();
            }
        }

        // 新增节点的逻辑
        lock.lock();
        try {
            // 再次检查容量，因为可能有其他线程在等待锁的过程中移除了节点
            if (map.size() >= capacity && !map.containsKey(key)) {
                Node removed = tail.prev;
                removeNode(removed);
                map.remove(removed.key);
            }
            
            Node newNode = new Node(key, value);
            map.put(key, newNode);
            addToFront(newNode);
        } finally {
            lock.unlock();
        }
    }
}

```

#### 二面

1. redis push命令怎么做幂等

- redis push命令做幂等的主要原因是，需要防止执行操作多次后添加了大量相同的数据。
- 我认为有两种可行的方法
- 第一种，可以使用Redis Set做去重控制，用List保存数据。通过向Set插入值，当值第一次出现的时候，再插入到List中。
- 第二种，可以使用Lua脚本把判断和插入操作封装成原子操作，在高并发场景下，Lua更安全更可靠
- 第三种，如果业务场景对幂等控制精度不高，可以借助布隆过滤器等轻量方案，在数据量特别大的场景下可以使用

```java
// 方法一
public void pushIfAbsent(String queueKey, String value, RedisTemplate<String, String> redisTemplate) {
    String dedupKey = queueKey + ":dedup"; // 幂等控制用的 Set

    // 向 Set 中添加，如果返回 true 表示是新数据
    Boolean isNew = redisTemplate.opsForSet().add(dedupKey, value);
    if (Boolean.TRUE.equals(isNew)) {
        // 如果是新数据，再写入 List 队列
        redisTemplate.opsForList().leftPush(queueKey, value);
    }
}

// 方法二
public void pushIfAbsentLua(String queueKey, String value, RedisTemplate<String, String> redisTemplate) {
    String dedupKey = queueKey + ":dedup";

    String luaScript =
        "if redis.call('SADD', KEYS[1], ARGV[1]) == 1 then " +
        "  return redis.call('LPUSH', KEYS[2], ARGV[1]) " +
        "else " +
        "  return 0 " +
        "end";

    DefaultRedisScript<Long> script = new DefaultRedisScript<>();
    script.setScriptText(luaScript);
    script.setResultType(Long.class);

    Long result = redisTemplate.execute(
        script,
        Arrays.asList(dedupKey, queueKey), // KEYS
        value                              // ARGV
    );

    System.out.println("Push result: " + result);
}

// 方法三
// 初始化布隆过滤器（可设置误判率为 0.01）
private static final BloomFilter<String> bloomFilter = BloomFilter.create(
    Funnels.stringFunnel(StandardCharsets.UTF_8),
    1_000_000,  // 预估插入元素数量
    0.01        // 可接受误判率
);

public void pushWithBloom(String queueKey, String value, RedisTemplate<String, String> redisTemplate) {
    if (!bloomFilter.mightContain(value)) {
        bloomFilter.put(value); // 标记为已处理
        redisTemplate.opsForList().leftPush(queueKey, value); // 插入队列
    }
}

```

2. 两张一亿条的excel表，主键相同，怎么合并写入磁盘

- 首先，将Excel转成csv，并按照主键排序，方便流式处理
- 进行合并
- 合并时可以优化内存，并发和IO操作
- 内存控制方面，可以使用BufferedReader和BufferWriter，不一次性加载到内存中（通过在内部维护一个默认大小为8k的缓冲区频繁访问磁盘实现）
- 可以根据主键范围，对主键范围分段，并使用线程池进行并发处理
- 每段的处理结果可以通过BufferedWriter写入磁盘，形成多个临时文件，或在指定合并结果位置的情况下，直接生成合并的文件
- 最后使用Java NIO或外部工具进行文件的合并，底层是OS的零拷贝机制，对IO操作进行了优化。

3. 算法题：（1）实现计算器（带+、-、*、/和括号） 

经典中缀转后缀表达式

4. 算法题：（2）知道两个矩形的左上和右下两个顶点，求交集矩形的顶点

范围