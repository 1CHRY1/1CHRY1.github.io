（线下面试）

## 科大讯飞一面

面试官中登一个，不显山不漏水的有点严肃

1. 自我介绍

2. 你们团队的组成结构，如何安排工作？
随便回答两个后端三个前端

3. 你们是如何提高查询效率的
回答用mysql存储元数据，添加空间索引和时间区间等联合索引提高查询效率，使用全球细分网格的形式做空间查询等等

4. 是如何做技术选型的，回答到以前用postgresql做数据查询现在选用了mysql，后问为什么修改，答更轻量级

5. 有没有在框架上有提升，说了业务解耦等等，答到了崩岸项目的数据源切换
当时回答：问的应该是SpringAOP的特性，讲了可以把日志模块拆出来等等

应该是想问有没有在已有框架上做封装和优化，比如：
- 在SpringSecurity中定制JWT解析过滤器，使服务内部不再重复解析token而是从Header中获取并验证用户ID是否有效
- 在MyBatisPlus基础上，新写一个BaseService封装分页查询，条件构造器转换，DTO/Entity转换逻辑等，并配合一个统一的返回结果
- 基于Feign做一个统一的拦截器，添加请求日志，链路追踪，熔断/重试策略等
- （我的项目）基于SpringAOP+ThreadLocal实现动态数据源切换。通过自定义注解并自定义AOP切面拦截，利用ThreadLocal保存当前数据源标识，在自定义AbstractRoutingDataSource中通过ThreadLocal获取标识，完成动态数据源切换
再深一点，mybatis执行sql的底层逻辑是：通过SqlSessionFactoryBuilder使用parse解析对应Configuration(xml)生成SqlSessionFactory，业务代码通过它创建SqlSession，执行SQL的时候委托给Executor，Executor再创建对应的SatementHandler并调用Transaction建立数据库连接，Transaction最终通过DataSource.getConnection拿到JDBC连接，SQL执行后由ResultSetHandler封装查询结果并返回给调用方。
而我系统中的数据源切换，则是发生在DataSource.getConnection()时，DataSource即是AbstractRoutingDataSource，会在getConnection时调用determineCurrentLookupKey()，根据当前的线程的ThreadLocal选择具体数据源

6. 问项目碰到的困难
讲了数据的全流程打通，讲了云平台部署环境迁移，讲了和甲方洽谈平衡需求

7. 问对AI大模型的了解，回答平时有用到，也考虑到在崩岸项目中接入大模型，也去尝试使用mcp技术等等

将大模型接入Java后端应用，可以通过：
- 把推理放到外部Model Serving / LLM Gateway并通过 REST/gRPC/HTTP 调用
- 把推理放到 JVM 进程内做本地推理。两者经常混合使用（云+边缘 + 本地加速 + 向量检索做 RAG），再配上模型控制/编排层和监控、治理、版本化、缓存与队列以满足生产要求。

自己找的开源项目：Bilibili的ai助手

mcp-server —— 提供服务功能，b站用户登陆，视频搜索，视频下载等（通过@Tool标识大模型能够调用的方法）
mcp-client —— 提供用户意图解析（获取关键字并识别成相关步骤，设置plan提取相关操作，最后调用mcp-server的相应接口实现）

8. 问除了java有没有了解其他内容，答springai，rpc框架，说到自己的项目如何实现，面试官听了没反问

9. 问觉得ai带来的影响
ai coding，ai在基本工作生活中的帮助，一些mcp应用等

反问业务，说是做ai数字人的
反问评价，说沟通很顺畅

---
总体上来看，还缺乏的一些素质有：
- 对大模型的了解，对主流大模型应用框架的了解
- 对SpringAOP在项目中应用的延申

## 科大讯飞二面

面试官很专业语速很快，不太喜欢问八股，点到为止，基本只问实操，我语速也很快，全流程不到半小时。以下问题先后可能有偏差

1. 自我介绍

2. 你觉得最优技术亮点的项目是哪个？
回答觉得1和3比较有亮点，1是因为全流程是自己做的，3是因为从框架上的创新等等

3. 看到项目1用了Redis，Redis是哨兵部署还是集群部署，这俩都有什么特点？
当时说的：一上来有点懵逼，秒答哨兵部署，回答哨兵会检查主从节点的状态，业务量不大所以没有用到集群，又解释集群部署是将大数据量拆分并分布在不同的主从节点中等等，这里语言表达的不够好，明显露怯了一些

Redis哨兵模式：主从复制结构（一台Master，多台Slave），加上Sentinel进程监控Master是否可用，若宕机则把一个Slave提升为Master。哨兵模式能够实现高可用和自动主备切换，部署相对简单，适合中小型项目；但没有数据分片，所有数据都在一个Master上，单机容量和性能优先，且扩展性差。
Redis集群模式：通过分片集群部署，数据根据哈希槽分布在多个Master上，每个Master都可以有多个Slave。解决了单机内存和性能瓶颈，并支持自动故障转移；通过数据分片突破单机内存限制，支持海量数据，主节点宕机自动从Slave中选举新的Master实现高可用。
因为数据规模不大，主要考虑高可用和自动故障转移和低部署成本，所以选用哨兵模式。如果要做大规模的数据存储和更高的并发，则会考虑Redis集群，能做分片扩容，突破单机瓶颈。


4. 看到用到了mysql，看到了查询优化问我是如何优化的？
当时说的：先讲明了系统设计的数据结构，后说用全球动态网格+空间索引提高空间查询效率，又用时间范围+卫星产品id联合索引实现普通的库表查询

这种问题可以先讲具体MySQL的优化方案，再讲具体项目。

MySQL的查询优化，可以用从SQL语句本身优化、索引优化、表结构优化、缓存与架构优化四个层面来入手：
- **语句优化**：只查询需要的字段而减少网络和IO；让where条件尽量走索引而避免在索引列上做函数或运算；LIMIT+覆盖索引，大分页查询的适合避免OFFSET扫描过多数据（用覆盖索引快速定位分页所需的主键，减少无效扫描和回表操作）；JOIN优化，用小表驱动大表，JOIN字段要有索引，减少多表关联
- **索引优化**，根据查询场景建立合适的单列或联合索引；遵循最左前缀匹配原则；针对高频字段建立覆盖索引；即使删除冗余索引
- **表结构和存储引擎优化**，选择合适的字段类型；对热点字段进行反范式设计；分区表、分库分表；innodb参数调优，比如增大innodb_buffer_pool_size让更多数据命中内存
- **执行计划与监控**，使用EXPLAIN分析查询计划，监控慢查询日志，对复杂SQL分解成多条简单SQL等

让我再次回答，我会说：
MySQL的优化就是从SQL语句优化，从索引上优化，从表结构上优化几种方案。
在SQL语句设计的时候我们在做简答的sql查询的时候，会通过索引覆盖的方式减少回表查询；
在索引设计的时候，我们通过设计空间索引做数据的高效空间查询；也通过设置时间范围+数据类型的联合索引提高非空间信息查询的数据检索方法
从表结构上，我们在接入海量硬件数据的时候采用根据数据类型、数据插入时间为分表依据，实现数据分表

5. 问到项目中的难点？
回答和上一面差不多

6. 问到使用了什么设计模式？
当时回答：单例模式，策略模式（模型计算模块），代理模式（RPC框架）

- 策略模式：
在卫星项目和崩岸项目中的建模应用场景中都用到了策略模式，两个项目中都存在地理信息模型调用的环节，为适配模型计算服务集群，我们统一实现了模型调用的接口，但针对不同的模型在调用、组装参数、状态查看的方法各有不同，因此使用了策略模式实现。
- 单例模式：
在自研高性能地理信息RPC框架中，为保证某些全局对象（如调用注册中心中的服务后，为实现直接二次调用时保存服务信息的缓存map，以及内部的连接信息）只初始化一次，就使用了单例模式。还有项目中一些基础的配置信息，如在线编程中的docker连接客户端，数据库连接池这些。
- 代理模式：
分布式项目中用到的很多，在我的自研RPC框架中，模型调用数据服务的时候，就是通过创建代理对象再调用的形式，就像调用本地方法一样，底层走的还是网络传输。SpringSecurity的认证拦截器也可以算是代理应用。

7. 看到用了kafka，问kafka为什么这么快
kafka没那么熟，但还好问的不深，就说了有不同的topic，每个topic在不同节点上可能有不同的partition，但是partition之间数据可能并非有序，然后提到消息队列内部也有时间序列，然后戛然而止下一个问题

然后开始了场景
8. 用过linux吗？答用过。问如果一个Java服务内存占用飙升怎么用linux命令查看？
当时回答：说平时是用top命令来查看各个进程的内存占用cpu占用等，Java内存占用应该有一个监控工具，可以用来查看堆内存，元空间等JVM区域的信息

当时回答还是太笼统了
- 基础排查：先用linux系统命令查看是不是Java进程占用异常，使用top/htop查看整体CPU/内存占用；再使用ps aux | grep java确认Java进程PID和内存占用；使用free -m查看系统整体内存使用情况；使用vmstat或iostat观察内存分页、IO是否异常；使用pmap -x <pid>查看进程内存空间分布，判断是堆、栈还是本地内存增长

- JVM内存层面
当确认是Java进程的问题后进入JVM层面排查
可以使用JDK所附带的一些检测工具，检测当前系统中运行的Java进程，监控JVM内存垃圾回收等统计信息等等。
具体实现步骤：
jps：找到Java进程的PID
jstat -gc <PID> 1000，试试查看堆内存使用，GC次数，判断是否频繁Full GC
jhsdb jmap --heap --pid 3232，查看内存中对象的实例数量和大小，定位可能的内存泄露点
jcmd 3232 GC.heap_info，更轻量地看堆信息。

- Java服务内存飙升也有可能是本地内存/DirectMemory/线程栈 造成的，可以配合top -H -p <PID>查看线程级别占用，结合jsack <PID>定位问题线程，cat /proc/<PID>/smaps查看详细内存分布，也可以在排查中结合监控系统或APM工具做更直观分析

总之可以通过：
第一步：用Linux命令确认问题，比如top查看进程的cpu、内存等字眼占用，用ps aux查PID，用pmap看内存分布。
第二部：进入JVM层面，可以用jstat查看GC情况，用jhsdb jmap jcmd查看堆分布以及对象占用情况。如果要深入分析，可以用jmap导出堆快照，用MAT或或VisualVM定位内存泄漏问题。
如果可能是线程或本地内存问题，可以用top -H -p配合jstack查看线程情况。

9. 问如果一个服务突然挂了/停了，你如何解决？

当时回答：说我们在系统内网部署了k8s+grafana这些监控组件，可以查看他们的网络IO，内存占用，cpu功耗信息。

首先确认故障，使用Prometheus+Grafana监控，有告警会第一时间通知。也可以使用kubectl get pods describe/logs查看日志报错信息，看是代码异常、连接失败还是内存溢出。

接着排查原因，可以从以下多个层面查看：
- 资源层面——查看各个服务的CPU、内存、网络IO等，可能存在内存泄漏或JVM配置不合理等问题
- 依赖层面——检查数据库是否异常、服务间调用是否超时
- 配置层面——查看是否有版本发布/配置更新等
- 代码层面——查看日志异常堆栈，是否有死循环、连接池耗尽等问题

快速恢复方法：
- 重启pod，恢复服务可用性
- 回滚版本，回退到旧版本
- 临时扩容，针对资源不足的情况可以临时扩容减缓压力

后续措施：
如果是内存溢出 → 用 jmap/jstat 导出堆分析。
如果是连接池耗尽 → 增加监控阈值并优化配置。
如果是外部依赖故障 → 加熔断 / 重试 / 降级策略。

预防：
加强监控指标和告警阈值（QPS、RT、错误率）。
压测和容量规划，避免生产环境直接 OOM。
健康检查 (livenessProbe/readinessProbe)，让 K8s 自动拉起服务。

总结一下：
问题可能出自三个方面：1资源问题，可以通过linux中的top/ps aux方案找到进程，针对进程使用jstat，jmap查看gc和堆占用状态等查看；可以通过扩展内存、增加cpu核数等方案实现优化。2依赖问题，数据库服务，队列服务等其他服务崩溃导致，可以通过加熔断、重试、降级等方式实现优化。3代码问题，可以同样通过查看服务的内存占用、堆占用，gc情况等，再查看日志是否有死讯含、连接池耗尽等问题，此时需要修改代码。

10. 接着上一个问题，碰到这种问题你会怎么做？（应该是问排查步骤）
当时回答：首先看后端应用日志，针对日志找到问题原因，如果有明显报错则修改；如果日志没有报错，就排查是否是Java服务内部堆内存等占用问题，用监控工具查看；如果还是没有，就查看是否是服务器维度的问题；后被打断

如上

11. 用IDE吗，用什么？有没有用过其中AI工具？
Idea，vscode。ai工具答的codex之类的，这个得做个调研。

cursor即可

一个chatgpt给出的prompt：

SYSTEM: 你是资深后端架构师和工程师助理。输出格式以 JSON 为主，内容简洁准确。
PROMPT:
我想做一个项目：{{一句话描述项目目的和用户，例如："遥感影像检索后端服务，支持上传、索引、时空查询与切片下载"}}。
技术栈：Java 17, Spring Boot 3, Spring Data, PostgreSQL+PostGIS, Elasticsearch, MinIO, Redis, Docker, Kubernetes。
非功能性要求：并发 QPS {{qps}}, 存储规模 {{size}} (例如 PB)、认证方式 JWT、必须支持健康检查和自动缩放。
请输出：
1. 简短需求摘要（5 条以内）。
2. 高层模块划分（每个模块 1-2 句功能描述）。
3. 建议的数据流（关键组件间调用关系）。
4. 初步接口列表（每个模块 3-6 个主要 API，含方法、路径、核心参数、返回类型说明）。
以 JSON 列表返回。

12. git相关问题，如何新建分支合并代码等等，标准化流程。

git：工作区 (add)-> 暂存区 (commit)-> 本地仓库 (push)-> 远程仓库

新建分支：git branch (-b) name
合并代码：
- 简单粗暴的方法：git pull origin main(直接把远程仓库拉取最新提交后，与本地当前分支合并。等于git fetch + git merge)
- 规范化的方法：git fetch origin main + git diff main/dev + git merge origin/main(从远程仓库中获取最新的分治信息和提交到本地的远程跟踪分支中，对比本地当前分支和远程跟踪分支的代码差异决定是否需要合并，最后将远程跟踪分支的更新合并到当前分支并更新本地代码)

git merge和git rebase的区别：
git merge创建新的合并提交，保留分支所有历史，适合公开分支间的整合；而git rebase则改写提交历史，使分支看起来基于目标分支最新版本开发的。

当在feature分支上执行git rebase master时，git会从master和featuer的共同祖先B开始提取feature分支上的修改，也就是C和D两个提交，先提取到。然后将feature分支指向master分支的最新提交上，也就是M。最后把提取的C和D接到M后面，注意这里的接法，官方没说清楚，实际是会依次拿M和C、D内容分别比较，处理冲突后生成新的C’和D’。一定注意，这里新C’、D’和之前的C、D已经不一样了，是我们处理冲突后的新内容，feature指针自然最后也是指向D’

总而言之，在使用github拉取更新代码的时候的标准操作是：
首先使用git fetch从远程库中获取最新分支信息到本地的远程跟踪分支中
在使用git diff origin/main对比本地当前分支和远程跟踪分支代码的差异，判断是否要合并
在使用git merge/rebase origin/main合并远程分支代码。其中merge主要用于主业务分支的合并，而rebase则将是在开发某新业务时将主分支业务最新内容合并在自己开发新业务之前，保证历史版本的的线性组织


13.  平时用AI吗？喜欢用哪些AI？
当时回答：用不同的AI做不同的事情。用Grok查资料（会生成一份查询文档），用ChatGPT做小而精的事情，因为回答内容精简而准确，用豆包做日常工作中的助手，因为他是客户端还提供了截图，解释，翻译等一系列功能。用kimi在手机端上查询问题，语音很方便看起来很丝滑。

14.  问最喜欢的AI？回答都喜欢。问哪个用的最多，回答豆包

反问
问业务：做公司系统中台的
后面的流程
给我一些建议：还是要多学习微服务相关的内容，包括场景解决的问题，承认对于校招生可能有点难等等。然后建议使用AI再激进一些，可以直接生成整个项目只要有合适的prompt

---
总体上来看，还缺乏的一些素质有：
Redis集群应用的了解，主要让自己的项目逻辑自洽
Java后台系统上线后的性能监控以及问题排查？包括内存激增，流量激增，突然挂掉之类的
kafka的一些场景准备吧
AI大模型问题，重新系统梳理一下如何在编程中使用AI大模型
git的应用

最后发感谢信了，总结了一下自己确实有太多东西没有准备完善，需要狠狠调整状态